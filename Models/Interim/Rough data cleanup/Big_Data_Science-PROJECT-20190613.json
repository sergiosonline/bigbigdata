{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{},"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441720255_-81135554","id":"20190613-160200_1615081668","dateCreated":"2019-06-13T16:02:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1104","dateUpdated":"2019-06-13T16:16:59+0000","dateFinished":"2019-06-13T16:16:59+0000","dateStarted":"2019-06-13T16:16:59+0000","title":"Problem Description","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>This project comes from Kaggle&rsquo;s &ldquo;Microsoft Malware Challenge.&rdquo; Imbalance ratio in data set is 1:10&ndash;namely, there is one computer in which malware has been detected for every 10 without detection.</p>\n</div>"}]},"text":"%md\nThis project comes from Kaggle's \"Microsoft Malware Challenge.\" Imbalance ratio in data set is 1:10--namely, there is one computer in which malware has been detected for every 10 without detection."},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{},"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441376492_-38277568","id":"20190613-155616_1219035123","dateCreated":"2019-06-13T15:56:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:629","dateUpdated":"2019-06-13T18:05:48+0000","dateFinished":"2019-06-13T16:02:02+0000","dateStarted":"2019-06-13T16:00:27+0000","title":"Data Loading, Checking, and Cleaning","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"file_location3: String = /user/betancourt_serest/data_randomized.csv\ndf3: org.apache.spark.sql.DataFrame = [MachineIdentifier: string, ProductName: string ... 81 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://cluster-1dde-ide-m.asia-northeast1-c.c.mie1628-bigbigdata.internal:4040/jobs/job?id=0","http://cluster-1dde-ide-m.asia-northeast1-c.c.mie1628-bigbigdata.internal:4040/jobs/job?id=1"],"interpreterSettingId":"spark"}},"text":"//val file_location3=\"/user/betancourt_serest/data_randomized.csv\"\n//val df3 = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\",\"true\").load(file_location3)\n\n/////// Counting number of nulls/nans per column\n//val col=df3.columns\n//var df3Array=col.map(colmn=>df3.select(lit(colmn).as(\"colName\"),sum(when(df3(colmn).isNull || df3(colmn)===\"\" || df3(colmn)===\"-\" || df3(colmn).isNaN,1).otherwise(0)).as(\"missingValues\")))\n\n//df3Array.tail.foldLeft(df3Array.head)((acc,itr)=>acc.union(itr)).show(false)\n\n/////// Counting number of distinct labels per column\n//import org.apache.spark.sql.functions._\n//val exprs1 = df1.columns.map((_ -> \"approx_count_distinct\")).toMap\n//df1.agg(exprs1).show()"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{},"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441759725_298726359","id":"20190613-160239_185541938","dateCreated":"2019-06-13T16:02:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1191","text":"//val file_location4=\"/user/betancourt_serest/data_reweighted.csv\"\n//val df4 = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\",\"true\").load(file_location3)","dateUpdated":"2019-06-13T18:06:39+0000","dateFinished":"2019-06-13T16:03:51+0000","dateStarted":"2019-06-13T16:03:51+0000","title":"Diagnosing and Cleaning up the Data","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441238499_1882814902","id":"20190613-155358_1037954292","dateCreated":"2019-06-13T15:53:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:232","text":"%md\nFor this and the below models---**three** in total---I will utilize an 80-20 training/test split, with stratified sampling and re-weighting throughout.","dateUpdated":"2019-06-13T16:27:58+0000","dateFinished":"2019-06-13T16:27:58+0000","dateStarted":"2019-06-13T16:27:58+0000","title":"","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>For this and the below models&mdash;<strong>three</strong> in total&mdash;I will utilize an 80-20 training/test split, with stratified sampling and re-weighting throughout.</p>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{},"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441965696_902235694","id":"20190613-160605_152234254","dateCreated":"2019-06-13T16:06:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1284","text":"%md\n#### Re-weighting Factor Definition\nLet R be the re-balancing ratio in your two-class dataset, N be your total number of observations, and X be the size of your overrepresented class. Then,\n$$R= \\frac{X}{N}$$\nBelow is the implementation of this principle as a new column to be added to the dataset:","dateUpdated":"2019-06-13T16:50:49+0000","dateFinished":"2019-06-13T16:32:01+0000","dateStarted":"2019-06-13T16:32:01+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Re-weighting Factor Definition</h4>\n<p>Let R be the re-balancing ratio in your two-class dataset, N be your total number of observations, and X be the size of your overrepresented class. Then,<br/>$$R= \\frac{X}{N}$$<br/>Below is the implementation as a new column to be added to the dataset</p>\n</div>"}]}},{"text":"//undersample negative (No Detections) class\nimport org.apache.spark.sql._\n\ndef rebalancedDataset(dataset: DataFrame): DataFrame = {\n\n    // Re-balancing (weighting) of records to be used in the logistic loss objective function\n    val numPositives = dataset.filter(dataset(\"HasDetections\") === 1).count\n    val datasetSize = dataset.count\n    val balancingRatio = (datasetSize - numPositives).toDouble / datasetSize\n\n    val calculateWeights = udf { d: Double =>\n      if (d == 0.0) {\n        1 * balancingRatio\n      }\n      else {\n        (1 * (1.0 - balancingRatio))\n      }\n    }\n\n    val reweightedDataset = dataset.withColumn(\"classWeightCol\", calculateWeights(dataset(\"HasDetections\")))\n    reweightedDataset\n  }\n  \n//val DFrebalancedData = rebalancedDataset(df3)\n//DFrebalancedData.select($\"classWeightCol\").show(10)","user":"anonymous","dateUpdated":"2019-06-13T18:06:11+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560443231327_-1331656917","id":"20190613-162711_710025342","dateCreated":"2019-06-13T16:27:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2049","dateFinished":"2019-06-13T16:38:37+0000","dateStarted":"2019-06-13T16:37:52+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql._\nrebalancedDataset: (dataset: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\nDFrebalancedData: org.apache.spark.sql.DataFrame = [MachineIdentifier: string, ProductName: string ... 82 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://cluster-1dde-ide-m.asia-northeast1-c.c.mie1628-bigbigdata.internal:4040/jobs/job?id=2","http://cluster-1dde-ide-m.asia-northeast1-c.c.mie1628-bigbigdata.internal:4040/jobs/job?id=3"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560444495675_1957950661","id":"20190613-164815_719140045","dateCreated":"2019-06-13T16:48:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5459","text":"//Splitting data into test and train\n//val fractions = Map(1 -> .8, 0 -> 0.8)\n//val DFtrain1 = DFrebalancedData.stat.sampleBy(\"HasDetections\", fractions, seed=1123)\n//val DFtest1 = DFrebalancedData.except(DFtrain1)\n//DFtest.agg(count(\"HasDetections\")).show()\n//DFtrain.filter($\"HasDetections\"===1).count()\n\n//Saving DF into HDFS\n//DFrebalancedData.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"data_reweighted.csv\")","dateUpdated":"2019-06-13T18:06:17+0000","dateFinished":"2019-06-13T17:57:58+0000","dateStarted":"2019-06-13T17:55:33+0000","results":{"code":"SUCCESS","msg":[]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://cluster-1dde-ide-m.asia-northeast1-c.c.mie1628-bigbigdata.internal:4040/jobs/job?id=10"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{},"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441256957_-599449320","id":"20190613-155416_1549554418","dateCreated":"2019-06-13T15:54:16+0000","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:384","text":"import org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.linalg.Vector\nimport org.apache.spark.sql._\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n\n\nval lr = new LogisticRegression()\n  .setMaxIter(10)\n  .setRegParam(0.001)\n  \nval paramGrid = new ParamGridBuilder()\n\t.addGrid(lr.regParam, Array(.1, .05, .01))\n\t.addGrid(lr.fitIntercept)\n\t.addGrid()\n\t.build()\n  \nval pipeline = new Pipeline().setStages(Array(tokenizer, hashingTF, lr))\n\nval model = pipeline.fit(training)\n\nmodel.transform(test)\n  .select(\"id\", \"text\", \"probability\", \"prediction\")\n  .collect()\n  .foreach { case Row(id: Long, text: String, prob: Vector, prediction: Double) =>\n    println(s\"($id, $text) --> prob=$prob, prediction=$prediction\")\n  }\n\nval d = model.transform(test)\n\nval evaluator = new BinaryClassificationEvaluator()\n\t.setLabelCol(\"label\")\n\t.setRawPredictionCol(\"rawPrediction\")\n\t\nval areaUnderROC = evaluator.setMetricName(\"areaUnderROC\").evaluate(predictions)\nval areaUnderPR = evaluator.setMetricName(\"areaUnderPR\").evaluate(predictions)","dateUpdated":"2019-06-13T16:49:36+0000","dateFinished":"2019-06-13T16:37:03+0000","dateStarted":"2019-06-13T16:37:02+0000","title":"Model 1 - Class-reweighted Logistic Regression","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.linalg.Vector\n<console>:26: error: object core is not a member of package org.apache.spark\n       import org.apache.spark.core._\n                               ^\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441967106_-1637359053","id":"20190613-160607_1508457395","dateCreated":"2019-06-13T16:06:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1500","text":"%pyspark\nprint(\"Hola\\n\\nSergio\")","dateUpdated":"2019-06-13T17:05:41+0000","dateFinished":"2019-06-13T17:05:41+0000","dateStarted":"2019-06-13T17:05:41+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Hola\n\nSergio\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441967017_-397220642","id":"20190613-160607_917001854","dateCreated":"2019-06-13T16:06:07+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1428"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{},"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441966909_953589217","id":"20190613-160606_490630291","dateCreated":"2019-06-13T16:06:06+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1356","dateUpdated":"2019-06-13T16:06:51+0000","title":"Model 2 - Class-Reweighted Random Forest"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560441255981_1140211075","id":"20190613-155415_1736982590","dateCreated":"2019-06-13T15:54:15+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:309"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{},"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560442014315_371804647","id":"20190613-160654_1229113550","dateCreated":"2019-06-13T16:06:54+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1732","dateUpdated":"2019-06-13T16:07:32+0000","title":"Model 3 - Boosted Trees (adaBoost/xgBoost)"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560442014243_873964449","id":"20190613-160654_1121453797","dateCreated":"2019-06-13T16:06:54+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1660"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560442013235_-242549860","id":"20190613-160653_2143575428","dateCreated":"2019-06-13T16:06:53+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1588"}],"name":"Big_Data_Science-PROJECT","id":"2EG1MCXF2","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}